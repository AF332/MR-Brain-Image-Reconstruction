{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYbuLZEHO_7s"
      },
      "source": [
        "First, TensorFlow and other libraries are imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cKdySowOiML"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "#from data import *\n",
        "\n",
        "#===========Read all data from files contained in folder from path\n",
        "def read_data(path, keyname):\n",
        "    data = []\n",
        "    h5name = os.listdir(path) # Read all the names of data in file (path) and store as a list\n",
        "\n",
        "    for i in range(len(h5name)): # Repeat for every fiel in folder from path\n",
        "        temp_path = path + '//' + str(h5name[i]) # Create a path for each file in the folder\n",
        "        tempdata = h5py.File(temp_path, \"r\") # Open h5 file as \"read\" and save as data\n",
        "        tempkeydata = tempdata[keyname] # Store data from 'kspace' key as kspacedata\n",
        "        data.append(tempkeydata) # Add data from key to list\n",
        "    data = np.array(data) # Turn list into numpy array\n",
        "    return data\n",
        "\n",
        "#==========Read Target Images\n",
        "def read_target_images(path):\n",
        "    data = read_data(path, 'reconstruction_rss') # Read dataset called reconstruction_rss in the h5 file\n",
        "    # Data is a numpy array: (4,18,256,256) (files, acquisitions, images pixels)\n",
        "    data_length = len(data) # store how many files have been read\n",
        "    images = [] # Generate empty variable\n",
        "    for i in range(data_length): # Repeat for the number of files in folder\n",
        "        d = data[i] # Save d as (18,256,256)\n",
        "        num_acq = d.shape[0] # Number of acquisitions in each file\n",
        "        for j in range(num_acq):  # Repeat for number of acquisitions\n",
        "            acquisition = d[j, ...] # Seperate image based on loop number\n",
        "            images.append(acquisition) # Add image to lits of images\n",
        "    images = np.array(images) # At the end of function turn list of images into numpu array\n",
        "    return images\n",
        "\n",
        "#==========Read Kspace Images and combine images from each coil fro each acquisition\n",
        "def read_source_images(path):\n",
        "    data = read_data(path, 'kspace') # Read dataset called reconstruction_rss in the h5 file\n",
        "    # Data is a numpy array: (4, 18, 4, 256, 256) (files, acquisitions, coils, imagex, imagey)\n",
        "    data_length = len(data) # store how many files have been read\n",
        "    kspace_data = [] # Generate empty variable\n",
        "    kspace_images = []\n",
        "    for i in range(data_length): # Repeat for the number of files in folder\n",
        "        d = data[i] # Save d as (18, 4, 256, 256)\n",
        "        num_acq = d.shape[0] # Number of acquisitions in each file\n",
        "        for j in range(num_acq):  # Repeat for number of acquisitions\n",
        "            acquisition = d[j, ...] # Seperate image based on loop number\n",
        "            kspace_data.append(acquisition) # Add image to lits of images\n",
        "            #This is simplified to average for now-------\n",
        "            coil0 = acquisition[0, ...]\n",
        "            coil1 = acquisition[1, ...]\n",
        "            coil2 = acquisition[2, ...]\n",
        "            coil3 = acquisition[3, ...]\n",
        "            kspace = (coil0+coil1+coil2+coil3)/4 # Coils added and averaged\n",
        "            #--------------------------------------------\n",
        "            kspace_images.append(kspace)\n",
        "    kspace_data = np.array(kspace_data) # At the end of function turn list of images into numpu array\n",
        "    kspace_images = np.array(kspace_images)\n",
        "    return kspace_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = read_source_images('//content//drive//MyDrive//DeepLearningProject//Training')\n",
        "test_images = read_source_images('//content//drive//MyDrive//DeepLearningProject//Testing')\n",
        "train_kspace_images = read_target_images('//content//drive//MyDrive//DeepLearningProject//Training')\n",
        "test_kspace_images = read_target_images('//content//drive//MyDrive//DeepLearningProject//Testing')\n",
        "print(train_kspace_images.shape) # Number of files(4)*acquisitions(18)\n",
        "print(test_kspace_images.shape)  # Number of files(2)*acquisitions(18)\n",
        "print(train_images.shape) # Number of files(4)*acquisitions(18)\n",
        "print(test_images.shape) # Number of files(2)*acquisitions(18)\n",
        "i_test = test_kspace_images # Size (36, 256, 256)\n",
        "i_train = train_kspace_images # Size (36, 256, 256)\n",
        "#train_kspace_images size = (36,256,256)\n",
        "#test_kspace_images size = (36,256,256)\n",
        "#train_images size = (36,256,256)\n",
        "#test_images size = (36,256,256)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zTBlMo_Pet-"
      },
      "source": [
        "Load the dataset from the mri brain images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngSznksNPktk"
      },
      "outputs": [],
      "source": [
        "(i_train, _), (i_test, _) = image #image is the image from gabriel's dataloding\n",
        "\n",
        "#Normalize the data\n",
        "i_train = i_train.astype('float32') / 255.\n",
        "i_test = i_test.astype('float32') / 255.\n",
        "\n",
        "print (i_train.shape)#image shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b116c-ojXArj"
      },
      "source": [
        "**Autoencoder**:\n",
        "\n",
        "Here I train a convolutional autoeconder using the function Conv2D layers. For the decoder, I use the function Conv2DTranspose layers.\n",
        "\n",
        "\n",
        "**Relu** is a non-linear function that replaces any negative values in the input with zero and leaves positive values unchanged.\n",
        "\n",
        "**Padding 'same'** means that additional rows and columns of zeros are added around the input data, so that the convolutional or pooling operation can be applied to every position.\n",
        "\n",
        "**Strides** control the step size at which the kernel moves: a stride of 1 means the kernel moves one pixel at a time. A larger stride results in a smaller output size because the kernel covers fewer positions.\n",
        "\n",
        "In regards to the layers.Conv2D:\n",
        "layers.Conv2D(filters, kernel_size, activation, padding, strides)\n",
        "\n",
        "Activation adam is an extension of the stochastic gradient descent optimization method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA3nHXVEXgL-"
      },
      "outputs": [],
      "source": [
        "class Denoise(Model):\n",
        "  def __init__(self):\n",
        "    super(Denoise, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([ #keras is used to add layers and improve the network\n",
        "      layers.Input(shape=(256, 256, 1)),#CHANGE THIS WHEN I KNOW THE SHAPE OF THE IMAGES\n",
        "      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=1),\n",
        "      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=1)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Denoise()\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "autoencoder.fit(i_train, image,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(i_test, image))\n",
        "\n",
        "encoded_imgs = autoencoder.encoder(i_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkaiSHvJZsbJ"
      },
      "source": [
        "Display the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezt3PPK1ZvLa"
      },
      "outputs": [],
      "source": [
        "# Display of original images and reconstructed images\n",
        "dispacq = 3  # Number of acquisitions to be displayed\n",
        "numcoil = len(acq[0])  # Number of coils\n",
        "\n",
        "for i in range(dispacq):\n",
        "    plt.subplot(2, dispacq, i + 1) # Create subplot to be scaled to number of acquisitions displayed\n",
        "    plt.imshow(abs(image), cmap='gray')\n",
        "    plt.title('Image Domain' + str(i), fontdict=font)\n",
        "    plt.subplot(2, dispacq, (i + dispacq+1))\n",
        "    plt.imshow(abs(decoded_imgs), cmap='gray')\n",
        "    plt.title('Reconstructed images' + str(i), fontdict=font)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
